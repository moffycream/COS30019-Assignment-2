{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os \n",
    "from skimage.transform import resize \n",
    "from skimage.io import imread \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import svm \n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report\n",
    "from joblib import dump, load\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Categories=['happy','sad'] \n",
    "flat_data_arr=[] #input array \n",
    "target_arr=[] #output array \n",
    "datadir='train/'\n",
    "# path which contains all the categories of images\n",
    "for i in Categories:\n",
    "    print(f'loading... category : {i}')\n",
    "    path = os.path.join(datadir, f'{i}_train')  # corrected directory path\n",
    "    for img in os.listdir(path):\n",
    "        img_array = imread(os.path.join(path, img))\n",
    "        img_resized = resize(img_array, (48, 48, 3))\n",
    "        flat_data_arr.append(img_resized.flatten())\n",
    "        target_arr.append(Categories.index(i))\n",
    "    print(f'loaded category:{i} successfully')\n",
    "\n",
    "flat_data = np.array(flat_data_arr)\n",
    "target = np.array(target_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe \n",
    "df=pd.DataFrame(flat_data) \n",
    "df['Target']=target \n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input data \n",
    "x=df.iloc[:,:-1] \n",
    "#output data \n",
    "y=df.iloc[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and testing sets \n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20, \n",
    "\t\t\t\t\t\t\t\t\t\t\trandom_state=123, \n",
    "\t\t\t\t\t\t\t\t\t\t\tstratify=y) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_dist = {'C': [0.1, 1, 10, 100],\n",
    "              'gamma': [0.0001, 0.001, 0.1, 1],\n",
    "              'kernel': ['rbf', 'poly']}\n",
    "\n",
    "model = svm.SVC(probability=True)\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=5, cv=5, random_state=123)\n",
    "random_search.fit(x_train, y_train)\n",
    "print(\"Best Parameters: \", random_search.best_params_)\n",
    "\n",
    "# Access the best model from the randomized search\n",
    "best_model_randomized = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the directory exists\n",
    "os.makedirs('svm', exist_ok=True)\n",
    "\n",
    "# Save the model to a file in the svm directory\n",
    "dump(best_model_randomized, 'svm/model.svm_model') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later, you can load the model from the file\n",
    "model = load('svm/model.svm_model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best model for predictions\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Evaluate accuracy on the test set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming 'model' is your SVM model\n",
    "train_accuracy_history = []\n",
    "test_accuracy_history = []\n",
    "\n",
    "# Train the model for different subsets of the training data\n",
    "for subset_size in range(10, len(x_train), 10):\n",
    "    # Use a subset of the training data\n",
    "    subset_x_train = x_train[:subset_size]\n",
    "    subset_y_train = y_train[:subset_size]\n",
    "\n",
    "    # Train the model on the subset\n",
    "    model.fit(subset_x_train, subset_y_train)\n",
    "\n",
    "    # Evaluate on the training set\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_accuracy_history.append(train_accuracy)\n",
    "\n",
    "    # Evaluate on the testing set\n",
    "    y_test_pred = model.predict(x_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_accuracy_history.append(test_accuracy)\n",
    "\n",
    "# Plot the learning curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(10, len(x_train), 10), train_accuracy_history, label='Training Accuracy')\n",
    "plt.plot(range(10, len(x_train), 10), test_accuracy_history, label='Testing Accuracy')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print (len(x_train))\n",
    "print (len(x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def predict_on_test_dataset(model, Categories, test_dir='test/'):\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    for category in Categories:\n",
    "        category_path = os.path.join(test_dir, f'{category}_test')\n",
    "        for img_name in os.listdir(category_path):\n",
    "            img_path = os.path.join(category_path, img_name)\n",
    "            \n",
    "            # Read the image\n",
    "            img = imread(img_path)\n",
    "            \n",
    "            # Display the image\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "            \n",
    "            # Resize the image\n",
    "            img_resize = resize(img, (48, 48, 3))\n",
    "            \n",
    "            # Flatten the image data\n",
    "            img_flat = img_resize.flatten()\n",
    "            \n",
    "            # Make a prediction\n",
    "            l = [img_flat]\n",
    "            prediction = model.predict(l)[0]\n",
    "            probability = model.predict_proba(l)\n",
    "            \n",
    "            # Display the prediction probabilities\n",
    "            for ind, val in enumerate(Categories):\n",
    "                print(f'{val} = {probability[0][ind] * 100}%')\n",
    "            \n",
    "            # Append true and predicted labels\n",
    "            true_labels.append(Categories.index(category))\n",
    "            predicted_labels.append(prediction)\n",
    "\n",
    "            # Display the predicted image category\n",
    "            print(\"The predicted image is: \" + Categories[model.predict(l)[0]])\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix, accuracy_score    \n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "    # Display confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=Categories, yticklabels=Categories)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "\n",
    "    # Display classification report\n",
    "    report = classification_report(true_labels, predicted_labels, target_names=Categories)\n",
    "    print('Classification Report:\\n', report)\n",
    "\n",
    "    print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "                \n",
    "# Call the function with your model and Categories\n",
    "predict_on_test_dataset(model, Categories)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
